[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gülhan Demirel Dilek’s Progress Journal",
    "section": "",
    "text": "This progress journal covers Gülhan Demirel Dilek / Time and Space’s work during their term at BDA 503 Fall 2022.\nEach section is an assignment or an individual work."
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "1  Assignment 1",
    "section": "",
    "text": "Hello everyone. I am Gülhan and I am currently working as a mathematics teacher. I have a mathematics education undergraduate degree from Boğaziçi University. I started to interest data as a hobby. In my trip of data, there were several areas to learn. One of them was Python which is a computer language to analyze data. Last February, I started the “100 Days of Code: The Complete Python Pro Bootcamp for 2022” certification program on Udemy. In addition to Python, HTML and CSS are also explained in the training. I was taking the training for a few hours every day after work. As the days progressed in the training, I started to enjoy it more and I spent 4-5 hours each evening and completed the training. Then, I started different training courses on data analytics on Udemy. I started two different courses, first in the statistics section and then in the field of SQL to improve my knowledge in both data extraction and analysis. As time passed, I was sure that I should do this job. However, after 5 years of teaching experience and because I do not have an academic background in data, I decided to pursue a master’s degree. So that’s why I’m here :)\nHere is my Linkedin profile"
  },
  {
    "objectID": "assignment1.html#rstudioconf2022",
    "href": "assignment1.html#rstudioconf2022",
    "title": "1  Assignment 1",
    "section": "1.2 rstudio::conf(2022)",
    "text": "1.2 rstudio::conf(2022)\n\n1.2.1 Garbage Data, And What To Do About Them by Jim Kloet\nThis video is about bad data. According to video bad data is the data that cannot be used for analysis or decision making. It identifies the challenges that you face while dealing with garbage data and suggest a framework to examine the bad data. Here are the steps: 1. Identify the garbage data: They are not usefull for the things you want to do, but maybe they are usefull for other stuff. You need to decide. If you chose none of them, you can destroy it. 2. Identify the costs of garbage data: Some costs are unavoidable and some costs are avoidable, but these can be catastrophic. 3. Take action when you see garbage data: There are options like being honest to your stakehoulders and being emphatatic to your stakehoulders to continue to have stakehoulders."
  },
  {
    "objectID": "assignment1.html#r-posts",
    "href": "assignment1.html#r-posts",
    "title": "1  Assignment 1",
    "section": "1.3 R Posts",
    "text": "1.3 R Posts\n\n1.3.1 Creating your career with R – data science based jobs!\nIt indicates that your industry and geographical location are the crucial factors that affect your career. That’s why a person who wants to improve modern data analytics skills like Hadoop, Weka, Natural Language Processing or Machine Learning should be in the countries that is open to new things. However, if you are living in a conservative country, SQL helps you to find a job. It says that R is the best way to start data based career and it should be supported by some other programs like SQL and Hadoop.\nPost Link\n\n\n1.3.2 Top Job Boards for R users to take your career to the next level!\nThe post says that R is one of the most important programming languages for Data Science applications. According to post, R is used for data manipulation, business analytics, machine learning algorithms and data visualization techniques. Here are some job boards that offers jobs in the fields of data science with R programming skills: R-users.com Dice CareerBuilder LinkedIn Indeed Monster Naukri Timesjobs\nPost Link\n\n\n1.3.3 Three Different Ways in How to Store Your Datasets in R\ndata.frame, data.table and data_frame are the common ways to store data in R.\ndata.frame is an internal package that is already in your computer. The drawback about data.frame is that strings are imported as factor. If you look at the example below, you can see the Names and Classes columns are imported as factor. Example:\n\nmydf = data.frame(Names = c(\"Paul\", \"Kim\", \"Nora\", \"Sue\", \"Paul\", \"Kim\"),\n                  Classes = c(\"A\", \"A\", \"B\", \"B\", \"B\", \"C\"),\n                  Points = rnorm(2)) \nmydf\n\n  Names Classes    Points\n1  Paul       A -0.290930\n2   Kim       A -1.960523\n3  Nora       B -0.290930\n4   Sue       B -1.960523\n5  Paul       B -0.290930\n6   Kim       C -1.960523\n\nsapply(mydf, class)\n\n      Names     Classes      Points \n\"character\" \"character\"   \"numeric\" \n\n\ndata.table saves time and helps to reduce errors because it is manipulated with less code and function calls. It has own structure like SQL. Example:\n\nlibrary(data.table,warn.conflicts = FALSE)\nmytable = data.table(Names = c(\"Paul\", \"Kim\", \"Nora\", \"Sue\", \"Paul\", \"Kim\"),\n                  Classes = c(\"A\", \"A\", \"B\", \"B\", \"B\", \"C\"),\n                  Points = rnorm(2)) \nmytable \n\n   Names Classes     Points\n1:  Paul       A -0.8496979\n2:   Kim       A -1.0848712\n3:  Nora       B -0.8496979\n4:   Sue       B -1.0848712\n5:  Paul       B -0.8496979\n6:   Kim       C -1.0848712\n\nsapply(mytable, class)\n\n      Names     Classes      Points \n\"character\" \"character\"   \"numeric\" \n\n\nIf you are using data_frame, you need columns of equal length. If not so, you will get an error messagge.\nAfter I run the code I got an error message that says “you should use tibble() instead of data_frame()”. So that is why I used tibble() in the following example. Example:\n\nlibrary(tibble)\nmy_df = tibble(Names = c(\"Paul\", \"Kim\", \"Nora\", \"Sue\", \"Paul\", \"Kim\"),\n                  Classes = c(\"A\", \"A\", \"B\", \"B\", \"B\", \"C\"),\n                  Points = rnorm(6)) \nmy_df                  \n\n# A tibble: 6 × 3\n  Names Classes Points\n  <chr> <chr>    <dbl>\n1 Paul  A        1.12 \n2 Kim   A       -0.976\n3 Nora  B       -1.57 \n4 Sue   B        1.11 \n5 Paul  B       -0.629\n6 Kim   C        0.393\n\nsapply(my_df, class)\n\n      Names     Classes      Points \n\"character\" \"character\"   \"numeric\" \n\n\nPost Link"
  },
  {
    "objectID": "inclass1.html",
    "href": "inclass1.html",
    "title": "2  In Class Exercise 1",
    "section": "",
    "text": "library(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "inclass1.html#the-number-of-planes-according-to-their-manufacturers.",
    "href": "inclass1.html#the-number-of-planes-according-to-their-manufacturers.",
    "title": "2  In Class Exercise 1",
    "section": "2.1 The number of planes according to their manufacturers.",
    "text": "2.1 The number of planes according to their manufacturers.\n\nplanes %>% \n  group_by(manufacturer) %>% \n  summarise(count=n()) %>% \n  arrange(manufacturer) %>% \n  print(n=35)\n\n# A tibble: 35 × 2\n   manufacturer                  count\n   <chr>                         <int>\n 1 AGUSTA SPA                        1\n 2 AIRBUS                          336\n 3 AIRBUS INDUSTRIE                400\n 4 AMERICAN AIRCRAFT INC             2\n 5 AVIAT AIRCRAFT INC                1\n 6 AVIONS MARCEL DASSAULT            1\n 7 BARKER JACK L                     1\n 8 BEECH                             2\n 9 BELL                              2\n10 BOEING                         1630\n11 BOMBARDIER INC                  368\n12 CANADAIR                          9\n13 CANADAIR LTD                      1\n14 CESSNA                            9\n15 CIRRUS DESIGN CORP                1\n16 DEHAVILLAND                       1\n17 DOUGLAS                           1\n18 EMBRAER                         299\n19 FRIEDEMANN JON                    1\n20 GULFSTREAM AEROSPACE              2\n21 HURLEY JAMES LARRY                1\n22 JOHN G HESS                       1\n23 KILDALL GARY                      1\n24 LAMBERT RICHARD                   1\n25 LEARJET INC                       1\n26 LEBLANC GLENN T                   1\n27 MARZ BARRY                        1\n28 MCDONNELL DOUGLAS               120\n29 MCDONNELL DOUGLAS AIRCRAFT CO   103\n30 MCDONNELL DOUGLAS CORPORATION    14\n31 PAIR MIKE E                       1\n32 PIPER                             5\n33 ROBINSON HELICOPTER CO            1\n34 SIKORSKY                          1\n35 STEWART MACO                      2"
  },
  {
    "objectID": "inclass1.html#max-engine-numbers-group-by-years.",
    "href": "inclass1.html#max-engine-numbers-group-by-years.",
    "title": "2  In Class Exercise 1",
    "section": "2.2 Max engine numbers group by years.",
    "text": "2.2 Max engine numbers group by years.\n\nplanes %>%\n  group_by(year) %>%\n  filter(duplicated(year)) %>%\n  arrange(year) %>%\n  mutate(\"max_engine_num\"=max(engines)) %>%\n  summarise(max_engine_num=paste0(unique(max_engine_num),collapse=',')) %>%\n  print(n=39)\n\n# A tibble: 39 × 2\n    year max_engine_num\n   <int> <chr>         \n 1  1959 1             \n 2  1963 1             \n 3  1975 2             \n 4  1976 2             \n 5  1977 2             \n 6  1978 2             \n 7  1979 2             \n 8  1980 2             \n 9  1984 2             \n10  1985 2             \n11  1986 3             \n12  1987 2             \n13  1988 2             \n14  1989 2             \n15  1990 4             \n16  1991 2             \n17  1992 2             \n18  1993 2             \n19  1994 2             \n20  1995 2             \n21  1996 2             \n22  1997 2             \n23  1998 2             \n24  1999 2             \n25  2000 2             \n26  2001 2             \n27  2002 2             \n28  2003 2             \n29  2004 3             \n30  2005 2             \n31  2006 2             \n32  2007 2             \n33  2008 2             \n34  2009 2             \n35  2010 2             \n36  2011 2             \n37  2012 2             \n38  2013 2             \n39    NA 4"
  },
  {
    "objectID": "inclass1.html#total-plane-count-per-engines.",
    "href": "inclass1.html#total-plane-count-per-engines.",
    "title": "2  In Class Exercise 1",
    "section": "2.3 Total plane count per engines.",
    "text": "2.3 Total plane count per engines.\n\nplanes %>%\n  group_by(engines) %>%\n  mutate(\"average_engine_nums\"=mean(engines, 1)) %>%\n  count(average_engine_nums)\n\n# A tibble: 4 × 3\n# Groups:   engines [4]\n  engines average_engine_nums     n\n    <int>               <dbl> <int>\n1       1                   1    27\n2       2                   2  3288\n3       3                   3     3\n4       4                   4     4"
  },
  {
    "objectID": "shiny_assignment.html",
    "href": "shiny_assignment.html",
    "title": "3  Shiny Assignment - Foreign Students by Nationality",
    "section": "",
    "text": "Here is my shiny app\nHere is the command line:\n\nshiny::runGitHub(\"pjournal/mef06-glhndmrl\",\n                 subdir=\"Foreign_Students_by_Nationality_Homework/\")"
  },
  {
    "objectID": "OR_assignment.html",
    "href": "OR_assignment.html",
    "title": "4  OR_assignment",
    "section": "",
    "text": "Emase is an e-commerce company which attract thousands of customers to participate in auctions of a wide array of physical products and leisure experiences such as vacations, spa, zoo, theme park packages, event tickets, and restaurant reservations.\nCompany had problems about timing and personalization. They send e-mails to customers in their ways but is was a manual process. It was time-consuming, and ineffective. E-mails need to be more relevant to indivual users. That’s why they decided to develop an automated, mathematical optimization tool to handle its email marketing campaigns."
  },
  {
    "objectID": "OR_assignment.html#the-solution-automation-and-optimization-of-the-email-marketing-process",
    "href": "OR_assignment.html#the-solution-automation-and-optimization-of-the-email-marketing-process",
    "title": "4  OR_assignment",
    "section": "4.2 The Solution: Automation and Optimization of the Email Marketing Process",
    "text": "4.2 The Solution: Automation and Optimization of the Email Marketing Process\nThey automate email marketing process and optimize the timing and personalization of the emails. Mathematical optimization was selected as the advanced analytics technology of choice for this application because of its flexibility and robustness.\nEach user’s unique auction bidding history helps them to determine which products to showcase.\nEach user’s personal contact preferences helps them to decide how many email users want to receive."
  },
  {
    "objectID": "OR_assignment.html#results",
    "href": "OR_assignment.html#results",
    "title": "4  OR_assignment",
    "section": "4.3 Results:",
    "text": "4.3 Results:\nNumber of sent emails increased 5%\nNumber of emails open by customers increased 5%\nInteraction to online auction platforms increased 6% using email campaigns\nRevenue assign increased 6% from email marketing"
  },
  {
    "objectID": "OR_assignment.html#source",
    "href": "OR_assignment.html#source",
    "title": "4  OR_assignment",
    "section": "4.4 Source:",
    "text": "4.4 Source:\nHere is the link of my source."
  }
]